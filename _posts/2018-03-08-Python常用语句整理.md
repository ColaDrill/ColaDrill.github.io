---
layout:     post
title:      Python常用语句整理
subtitle:   For Data Mining
date:       2018-03-08
author:     Jiayue Cai
header-img: img/post-bg-debug.png
catalog: true
tags:
    - Machine Learning

---


>Last updated on 2018-8-19... 

### 常用头文件 

	import numpy as np               #数学
	import pandas as pd              #表格
	from pandas import Series,DataFrame
    import matplotlib.pyplot as plt  #图形
    %matplotlib inline

	
### 特征工程（简单）

	df = pd.read_csv("data/train.csv")
	df.describe()                    #各项统计
	df.info()                        #看总数及数值类型 

####缺失值处理（对于竞赛而言最好不要直接删除，最好另作特殊编码）

	df = df.drop(['PassengerId','Name','Ticket','Cabin'], axis=1)  #对于大量缺失数据的列可直接删除
    df = df.dropna()                                               #删除含有NaN数据的行
    df['Embarked'] = df['Embarked'].fillna('S')                    #离散值填充众数  
	median_age = train['Age'].median()                             #连续值填充中位数（或者平均值）
    df['Age'] = df['Age'].fillna(median_age)
	
####数据格式转换（其实就相当于简易的编码，需根据分类器的特性来）

    df.loc[ (df.Sex == 'male'), 'Sex' ] = 0    #令男为0
    df.loc[ (df.Sex == 'female'), 'Sex' ] = 1  #令女为1
	df['Sex'] = df['Sex'].map( {'male': 0, 'female': 1} ).astype(int) #这种写法更好
	
####合并相似特征

	###1、称谓
	df['Title'] = df['Name'].str.extract('([A-Za-z]+)\.', expand=False)
    df['Title'] = df['Title'].fillna('NoTitle')
    df['Title'] = df['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')
    df['Title'] = df['Title'].replace(['Mlle','Ms'], 'Miss')
	df['Title'] = df['Title'].replace('Mme', 'Mrs')
	
	###2、亲戚数量与子女数量
    df['Companions'] = df['Parch'] + df['SibSp']
    to_be_dropped.extend(['Parch', 'SibSp'])

### 特征工程（进阶）

####单值连续特征(连续编码)

	from sklearn.preprocessing import OneHotEncoder,LabelEncoder
	one_hot_feature=['LBS','age','carrier','consumptionAbility','education','gender','house','os','ct','marriageStatus']
	for feature in one_hot_feature:   	          #LabelEncoder将各种标签分配一个可数的连续编号
		try:
			data[feature] = LabelEncoder().fit_transform(data[feature].apply(int))
		except:
			data[feature] = LabelEncoder().fit_transform(data[feature])
			
	enc = OneHotEncoder()                         #one-hot表示（这一步须结合分类器特性）
	for feature in one_hot_feature:
		enc.fit(data[feature].values.reshape(-1, 1))
		train_a=enc.transform(train[feature].values.reshape(-1, 1))
		test_a = enc.transform(test[feature].values.reshape(-1, 1))
		train_x= sparse.hstack((train_x, train_a))
		test_x = sparse.hstack((test_x, test_a))
	
	
####多值特征（top编码）

	from sklearn.preprocessing import LabelEncoder
	vecc = vec['interest1'].value_counts()[:2000]  #代表出现数量前2000名的兴趣子片段，调大可提高精度
	vecc_Fragment = vecc.index.tolist()
	vecc_laber_encoder = LabelEncoder().fit_transform(vecc_Fragment)
	vecci = dict(zip(vecc_Fragment,vecc_laber_encoder))
	
####统计特征

	###1、长度
	vector_feature=['interest1','interest2','interest5','kw1','kw2','topic1','topic2']
	for feat in vector_feature:                    
		data['len_'+feat] = data[feat].apply(lambda x:0 if ((not x.strip()) or str(x)=='-1') else len(x.split(' ')))
		
	###2、平均值
	data['meanlen_interest'] = (data['len_interest1']+data['len_interest2']+data['len_interest5'])/3.0
	
    ###3、最大值
	data['max_ct'] = data['ct'].apply(lambda x: 0 if ((not str(x).strip()) or str(x)=='-1') else max(int(i) for i in str(x).split(' ')))  
	
	###4、分层
	df.loc[ df['Age'] <= 16, 'Age'] = 0
    df.loc[ (df['Age'] > 16) & (df['Age'] <= 32), 'Age'] = 1
    df.loc[ (df['Age'] > 32) & (df['Age'] <= 48), 'Age'] = 2
    df.loc[ (df['Age'] > 48) & (df['Age'] <= 64), 'Age'] = 3
    df.loc[ df['Age'] > 64, 'Age'] = 4
    df['Age'] = df['Age'].astype(int)
	
####转化率特征（命中率）

	num_ad = train['aid'].value_counts().sort_index()
	num_ad_clicked = data_clicked['aid'].value_counts().sort_index()
	ratio_ad_clicked = num_ad_clicked / num_ad
	ratio_ad_clicked = pd.DataFrame({
		'aid': ratio_ad_clicked.index,
		'ratio_ad_clicked' : ratio_ad_clicked.values
	})
	data = pd.merge(data, ratio_ad_clicked, on=['aid'], how='left')
	
####归一化

	###将新加入的特征归一化
	from sklearn.preprocessing import StandardScaler
	scaler = StandardScaler()
	scaler.fit(train[['ratio_ad_clicked', 'num_ad_push2user']].values)
	train_x = scaler.transform(train[['ratio_ad_clicked', 'num_ad_push2user']].values)
	
	
### 模型调用（简单）
	
	X_test = pd.read_csv("data/test.csv")
	from sklearn.svm import SVC, LinearSVC
	svc = SVC()
	svc.fit(df, dfs)
	Y_pred = svc.predict(X_test)
	svc.score(df, df.Survived)

### 模型调用（进阶）

	def LGB_predict(train_x,train_y,test_x,res):
		print("LGB test")
		clf = lgb.LGBMClassifier(
			boosting_type='gbdt', num_leaves=31, reg_alpha=0.0, reg_lambda=1,zero_as_missing=True,
			max_depth=-1, n_estimators=500, objective='binary',
			subsample=0.9, colsample_bytree=0.8, subsample_freq=1,
			learning_rate=0.1, min_child_weight=50, random_state=2018, n_jobs=100
		)
		clf.fit(train_x, train_y, eval_set=[(train_x, train_y)], eval_metric='auc',early_stopping_rounds=100)
		res['score'] = clf.predict_proba(test_x)[:,1]
		res['score'] = res['score'].apply(lambda x: float('%.6f' % x))
		res.to_csv('../data/submission.csv', index=False)
		os.system('zip baseline.zip ../data/submission.csv')
		return clf

	model=LGB_predict(train_x,train_y,test_x,res)
	
### 使用管道

    df = pd.read_csv('data/train.csv')
    y = df.author.values
    X = df.text.values

    df2 = pd.read_csv('data/test.csv')
    X2 = df2.text.values
	
	from sklearn.pipeline import Pipeline
    from sklearn.feature_extraction.text import CountVectorizer
    from sklearn.feature_extraction.text import TfidfTransformer
    from sklearn import svm
	
	text_clf = Pipeline([('vect', CountVectorizer()),
                     ('tfidf', TfidfTransformer()),
                     ('clf', svm.LinearSVC())
                    ])
    text_clf = text_clf.fit(X,y)
    y2 = text_clf.predict(X2)
    y2
	
### 输出表格

    submission = pd.DataFrame({
        "PassengerId": test_df["PassengerId"],
        "Survived": Y_pred
    })
    submission.to_csv('C:/Users/caijiayue/Desktop/titanic2.csv', index=False)
	
### One-hot输出

    from sklearn import preprocessing
    encoder = preprocessing.LabelBinarizer()
    encoder.fit(list(set(y2)))
    one_hot_labels = encoder.transform(y2)                         
	prediction = pd.DataFrame(one_hot_labels, columns=['EAP','HPL','MWS']).to_csv('C:/Users/caijiayue/Desktop/author-pre.csv')