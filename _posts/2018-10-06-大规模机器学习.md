---
layout:     post
title:      大规模机器学习
subtitle:   For Data Mining
date:       2018-10-06
author:     Jiayue Cai
header-img: img/post-bg-rwd-big_data.jpg
catalog: true
tags:
    - Machine Learning
    - Big Data
---


>Last updated on 2018-10-6，未完待续... 

原文来自《美团机器学习实践》，Target：海量数据下的机器学习应用场景

![1](https://upload-images.jianshu.io/upload_images/13187322-425ab78ed0418167.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp)

### 并行计算编程技术

- CPU单核：通过`向量化技术`来提升单核的处理能力
- CPU多核：通过`多线程技术`来充分利用多核处理能力
- GPU：通过`异构计算`来扩充单机的处理能力
- 多机并行：把多机串联起来组成计算集群

#### 向量化

**费林分类法**：

|              |**单一指令流**          |**多指令流**            |
|--------------|------------------------|------------------------|
|**单一数据流**|单指令流单数据流（SISD）|多指令流单数据流（MISD）|
|**多数据流**  |单指令流多数据流（SIMD）|多指令流多数据流MIMD）  |

单指令流多数据流（Single Instruction Multiple Data，SIMD）是一种采用一个控制器来控制多个处理器，同时对一组数据（又称“数据向量”）中的每一个分别执行相同的操作从而实现空间上的并行性的技术。
- 在微处理器中，单指令流多数据流技术则是一个控制器控制多个平行的处理微元，例如Intel的MMX或SSE，以及AMD的3D Now!指令集。
- 图形处理器（GPU）拥有强大的并发处理能力和可编程流水线，面对单指令流多数据流时，运算能力远超传统CPU。OpenCL和CUDA分别是目前最广泛使用的开源和专利通用图形处理器（GPGPU）运算语言。

在X86架构的CPU上：（PC端）
- [SSE指令集](https://zh.wikipedia.org/wiki/SSE)（Streaming SIMD Extensions, 单指令多数据流式扩展）：16个128位的寄存器，每一个寄存器可存放4个（32位）单精度浮点数，这些数就可以在寄存器中进行算术逻辑运算，然后把结果放回内存
- [AVX指令集](https://zh.wikipedia.org/wiki/AVX%E6%8C%87%E4%BB%A4%E9%9B%86)（Advanced Vector Extensions，高级向量扩展）：扩充为256位，从而支持256位的矢量计算，理论上性能提升1倍

在ARM架构的CPU上：（移动端）
- Neon指令集：16个128位的寄存器

**在理想状况下，SSE指令集的加速比位4倍，AVX是8倍。不过实际过程中，由于加载数据到寄存器有时间消耗，加速比略低于这个理论值**









