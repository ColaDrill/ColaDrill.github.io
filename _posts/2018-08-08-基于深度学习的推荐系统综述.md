---
layout:     post
title:      基于深度学习的推荐系统综述
subtitle:   Focus on deep learning
date:       2018-08-08
author:     Jiayue Cai
header-img: img/post-bg-debug.png
catalog: true
tags:
    - Deep Learning
    - Recommending System
---


>Last updated on 2018-8-8... 还未全部写完

本文是对发表在ACM 2017的《Deep Learning based Recommender System: A Survey and New Perspectives》一文的笔记，作梳理用。
[》原文链接](https://arxiv.org/pdf/1707.07435.pdf)

### 数据集和评估指标

常用数据集：[Movielens](https://grouplens.org/datasets/movielens/)、[Netflix](https://www.kaggle.com/netflix-inc/netflix-prize-data)、[Amazon](http://jmcauley.ucsd.edu/data/amazon/links.html)、[Yelp](https://www.yelp.com/dataset_challenge)、[CiteUlike](http://www.citeulike.org/faq/data.adp)
评估指标分类：
- rate prediction evaluation：均方根误差（RMSE）、平均误差（MAE）
- evaluate the ranking scores：精确度、召回率、标准化折扣累积增益（NDCG）、曲线下面积（AUC）
- classifcation result evaluation：精确度、召回率、F1-score

### 模型介绍

作者采用了二维分类方案，即神经网络模型和集成模型：
![基于深度学习的推荐系统分类的二维方案](https://upload-images.jianshu.io/upload_images/13187322-63bc9949059b65d4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/640)

#### MLP 多层感知器

一种前馈神经网络，在输入层和输出层之间具有多个（一个或多个）隐藏层。这里，感知器可以使用任意激活函数，并不一定代表严格的二元分类器。
特点：可以轻松地模拟用户和项目之间的非线性交互
- `NCF 神经协同过滤`（U和V分别embedding然后一起CF layer）：结合了矩阵分解（将分级矩阵分解为低维潜在用户空间和低维潜在项目空间）和基于内容的推荐系统（基于用户配置文件和项目特征之间的相似性生成推荐列表）的思想，构建了`双网络`以建模用户和项目之间的双向交互。
- `CCCFNet 跨域内容提升的协同过滤神经网络`：基本组合也是双网络（分别针对用户和项目）。 它使用点积来模拟最后一层中的用户项交互。 为了嵌入内容信息，作者进一步将双网的每个网络分解为两个组成部分：协同过滤因子（用户和项目潜在因素）和内容信息（用户对项目特征和项目特征的偏好）。 
- `Wide & Deep模型`（将LR与FM+NN并行最后一起sigmoid）：Wide学习组件实现的记忆代表了从历史数据中捕获直接特征的能力。 同时，Deep学习组件通过产生更一般和抽象的表示来捕捉泛化。
- `DeepFM 深度分解机`（一边原始特征和embedding一起FM，一边embedding后NN，最后一起sigmoid）： 使用FM的神经解释取代了Wide组件。FM利用加法和内积运算来捕获特征之间的线性和成对相互作用；MLP利用非线性激活和深层结构来模拟高阶交互。

*将MLP与传统推荐系统集成：
- [Attentive CF](https://www.comp.nus.edu.sg/~xiangnan/papers/sigir17-AttentiveCF.pdf)：作者通过在潜在因子模型中引入两级保持机制，提出了一种临时协同过滤模型。注意力模型是由项目级别和组件级别的注意力组成的MLP：项目级别的注意力用于选择最具代表性的项目来表征用户；组件级别的注意力旨在从每个用户的多媒体辅助信息（multimedia auxiliary information）中捕获最丰富的信息。（注意力机制能够从原始输入中滤除无信息特征，并减少噪声数据的副作用。）

#### AE 自动编码器

一种无监督模型，试图在输出层重建其输入数据。通常，bottleneck层（最中间层）用作输入数据的显着特征表示。 自动编码器有许多变体，例如去噪自动编码器、边缘化去噪自动编码器、稀疏自动编码器、收缩自动编码器和变分自动编码器（VAE）。
将自动编码器应用于推荐系统有两种通用方法：利用自动编码器学习bottleneck层的低维特征表示; 或者直接在重建层中填充评级矩阵的空白。
- `AutoRec`：将用户部分向量r<sup>(u)</sup>或项目部分向量r<sup>(i)</sup>作为输入(对应I-AutoRec和U-AutoRec)，旨在输出层中重构它们。 
- `CFN 协同过滤神经网络`：是AutoRec的扩展，具有以下两个优点：采用了去噪技术，使CFN更加健壮; 结合了诸如用户配置文件和项目描述之类的辅助信息，以减轻稀疏性和冷启动影响。
- `ACF 基于自动编码器的协同过滤`：它不是使用原始的部分观察向量，而是通过整数等级对它们进行分解。例如，如果评级分数是[1-5]范围内的整数，则每个r<sup>(i)</sup>将被分成5个部分向量。然而，ACF有两个缺点：无法处理非整数等级; 部分观测矢量的分解增加了输入数据的稀疏性，导致预测精度更差。
- `CDAE 协同去噪自动编码器`：该模型主要用于排名预测，最初使用SGD在所有反馈上更新其参数。作者认为在实际应用中考虑所有评级是不切实际的，因此提出了一种负抽样技术来从负集合（用户没有与之交互的项目）中抽取一小部分，这样减少了时间复杂度且基本上没有降低排名质量

*将AE与传统推荐系统集成：
紧耦合模型同时学习自动编码器和推荐器模型的参数，使推荐器模型能够为自动编码器提供指导，以学习更多的语义特征:
- `CDL 协作深度学习`：一种分层贝叶斯模型，它将堆叠去噪自动编码器（SDAE）集成到概率矩阵分解中。 由两个紧密联系的组件组成：感知组件（深度神经网络）和任务特定组件。 具体而言，CDL的感知成分是序数SDAE的概率解释，PMF充当任务特定成分。
- `CDR 协作深度排名`：该模型是在成对框架中专门为top-n推荐设计的。 CDL是最初为评级预测提出的逐点模型，然而研究表明成对模型更适合排序列表生成。 实验结果还表明CDR在排名预测方面优于CDL。
- `DCFF 深层协同过滤框架`（item隐特征V x user隐特征U = R）：该模型是协同过滤结合深度学习的一般框架，该框架使得更容易利用深度特征学习技术来辅助协作推荐。
松耦合模型分两步执行：通过自动编码器学习显着特征表示，然后将这些特征表示馈送到推荐系统:
- `AutoSVD++`：利用收缩自动编码器来学习项目特征表示，然后将它们集成到经典推荐模型SVD++中。 所提出的模型具有以下优点：与其他自动编码器变体相比，压缩自动编码器捕获了无穷小的输入变化;对隐式反馈进行建模，以进一步提高准确性;设计了一种有效的训练算法来减少训练时间。
- `HRCD`：一种基于自动编码器和timeSVD ++的混合协作模型。它是一种时间感知模型，使用SDAE从原始特征中学习项目表示，旨在解决冷项目问题，但用于冷项目推荐的基于相似性的方法在计算上是昂贵的。

#### CNN 卷积神经网络

一种特殊的前馈神经网络，具有卷积层和池化层。它能够捕获全局和局部特征，并显着提高效率和准确性。它在处理具有网格状拓扑的数据方面表现良好。
特点：能够从异构数据源（如文本和视觉信息）中提取本地和全局表示。
- `Attention based CNN`：模型包括全球信道和本地信道：全局通道由卷积滤波器和最大池层组成，所有单词都在全局通道的输入中编码；本地保留信道具有具有给定窗口大小h和阈值η的保留层，以选择信息性词语（在该工作中称为触发词）。 

*将CNN与传统推荐系统集成：
紧耦合模型：
- `DeepCoNN 深度协同神经网络`（用户网络和项目网络的输出最终连接为FM的输入）：采用两个并行卷积神经网络来模拟评论文本中的用户行为和项目属性，在最终层中FM用于捕获它们的相互作用以进行评级预测。 它通过利用复杂文本的丰富语义表示来缓解稀疏性问题并增强模型可解释性；利用单词嵌入技术将评论文本映射到较低维度的语义空间，并保留单词序列信息；提取的评论表示然后连续地通过具有不同内核，最大池化层和全连接层的卷积层。 
- `ConvMF`：与CDL类似的方式将CNN与PMF相结合。CDL使用自动编码器来学习项目特征表示，而ConvMF使用CNN来学习高级项目表示。 ConvMF相对于CDL的主要优点是CNN能够通过世界嵌入和卷积内核捕获更准确的项目上下文信息。
松耦合模型（根据CNN处理的特征类型分为以下三类）：
- `（用于图像特征提取）`VPOI模型： VPOI采用CNN提取图像特征，通过探索 视觉内容和潜在用户因素 以及 视觉内容和潜在位置因素 之间的相互作用，是建立在PMF上的推荐模型。
- `（用于音频特征提取）`使用CNN从音乐信号中提取特征，其卷积内核和池化层允许多个时间段的操作。 这种基于内容的模型可以缓解音乐推荐的冷启动问题。
- `（用于文本特征提取）`使用CNN从学习资源的文本信息中提取项目特征。

#### RNN 递归神经网络

适用于对序列数据建模。与前馈神经网络不同，RNN中存在循环和记忆以记住以前的计算。诸如长短期存储器（LSTM）和门控循环单元（GRU）网络的变体在实践中被部署以克服消失的梯度问题。
特点：使推荐系统能够对评级数据的时间动态和内容信息的连续影响进行建模
- `基于会话的RNN推荐模型`（session或cookie机制使得系统能够获得用户的短期偏好）：输入是具有1-N编码的实际会话状态，其中N是项目数。如果相应的项目在此会话中处于活动状态，则坐标将为1，否则为0。输出是每个项目在会话中成为下一个项目的可能性。
- `RRN 经常性推荐网络`：它能够模拟项目的季节性演变和用户偏好随时间的变化。 
- `Neural Survival Recommender 患者生存分析模型`：作者提出了一个多任务学习框架以预测患者的生存时间。
- `Attention based RNN`：利用RNN和注意机制的优势来捕获顺序属性并识别来自微博帖子的信息性词语。该模型使用LSTM学习隐藏状态用于微博帖子，使用主题模型LDA来学习帖子的主题分布，经过一系列非线性变换和softmax归一化，最后通过最小化交叉熵来训练这个模型。

*将RNN与传统推荐系统集成：


#### DSSM 深度语义相似度模型

也称作深度结构化语义模型，是一种深度神经网络，用于学习公共连续语义空间中实体的语义表示并测量它们的语义相似性。
特点：能够在用户和项目之间执行语义匹配

#### RBM 受限玻尔兹曼机

一个由可见层和隐藏层组成的双层神经网络。它可以很容易地堆叠到深层网络。此处受限制意味着可见层或隐藏层中没有层内通信。

#### NADE 神经自回归分布估计

一种在自回归模型和前馈神经网络之上构建的无监督神经网络。 它是用于建模数据分布和密度的易处理且有效的估计器。

#### GAN 生成对抗网络

一种生成神经网络，由判别网络和生成网络组成。 通过在minimax game framework中相互竞争，同时训练两个神经网络。





