---
layout:     post
title:      强化学习的泛化能力问题
subtitle:   鲁棒性优化、环境随机化、启发式正则、sim2real
date:       2020-05-16
author:     Jiayue Cai
header-img: img/post-bg-ai.jpg
catalog: true
tags:
    - Reinforcement Learning
---


> Last updated on 2020-05-17... 

目前大部分强化学习论文使用的主要基准任务实际上都是偏弱的，比如MuJoCo或者Atari，更不用说前两年`MARL`用的[multiagent-particle-envs](https://github.com/openai/multiagent-particle-envs)。
在偏弱的实验环境里，模型跑出来的结果看起来尚可，模型的许多问题暴露得不明显就不会引起大家的广泛关注，因此相关的研究也就会比较少。 
而强化学习的泛化能力问题，就是这些问题之一。

> 往期相关传送门：[《强化学习总览》](https://coladrill.github.io/2018/12/02/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E6%80%BB%E8%A7%88/)、[《深度强化学习综述》](https://coladrill.github.io/2018/10/21/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%BB%BC%E8%BF%B0/)、[《强化学习在推荐系统中的应用》](https://coladrill.github.io/2018/11/15/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/)、[《推荐系统的发展与简单回顾》](https://coladrill.github.io/2019/12/10/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%8F%91%E5%B1%95%E4%B8%8E%E7%AE%80%E5%8D%95%E5%9B%9E%E9%A1%BE/)

### 理论与实践的差异

> [《炼丹感悟：On the Generalization of RL》](https://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247503049&idx=2&sn=1164dcccb7cede8d75a743f9739b1c0f&chksm=96ea1349a19d9a5f792e91088096c2ecbb2dac7a00b6c373eb9848bd87234c97996cbaf89a5f&mpshare=1&scene=23&srcid=0212S6vjRE8w0vvZdvG3o1Zo&sharer_sharetime=1581473512553&sharer_shareid=cc983be31429dfbd5199d63f0d94b825#rd)

**理论层面**，由于强化学习本身的理论建模中不存在泛化问题，目前学术界的研究大部分都是经验性的工作，理论性文章很少。 

**实践层面**，最大的困难来自于当前`model-free RL`模型高方差的问题，工业界的场景远比学术界所常用的MuJoCo和Atari任务复杂

因此，在 MuJoCo、Atari和随机迷宫之类的环境中，如果你做出了某种提升，可能提升的幅度还不如代码层面优化换`random seed`或者`reward scaling`来的明显，今年ICLR就有一篇讲RL的`code-level optimization`的文章工作被接受，足以说明现在的RL研究者对可复现性（reproducibility）的殷切期盼。

基本上大多数研究 RL generalization 或 robustness 的文章里都会涉及到，举一些代表性的例子： 

|    **过拟合于状态特征**     | [Observational Overfitting in Reinforcement Learning](https://arxiv.org/pdf/1912.02975.pdf)|
|    **动作空间的随机性**     | [Action Robust Reinforcement Learning and Applications in Continuous Control](https://arxiv.org/pdf/1901.09184.pdf)|
|  **连续控制任务上的过拟合** | [Dissection of Overfitting and Generalization in Continuous Reinforcement Learning](https://arxiv.org/abs/1806.07937.pdf)|
|    **死记硬背型过拟合**     | [A Study on Overfitting in Deep Reinforcement Learning](https://arxiv.org/abs/1804.06893.pdf)、[Quantifying Generalization in Reinforcement Learning](https://openai.com/blog/quantifying-generalization-in-reinforcement-learning/)|
|       **环境动态**           | [Planning with Information-Processing Constraints and Model Uncertainty in Markov Decision Processes](https://arxiv.org/abs/1604.02080.pdf)|

### 环境随机化


### 鲁棒性优化


### 启发式正则


### sim2real


未完待续...


