---
layout:     post
title:      自动机器学习总览
subtitle:   A Survey on Automated Machine Learning
date:       2018-12-07
author:     Jiayue Cai
header-img: img/post-bg-ai.jpg
catalog: true
tags:
    - Machine Learning
    - Automated Machine Learning
---


> Last updated on 2018-12-07...

- [元学习博客链接](https://coladrill.github.io/2018/10/24/%E5%85%83%E5%AD%A6%E4%B9%A0%E6%80%BB%E8%A7%88/)
- [强化学习博客链接](https://coladrill.github.io/2018/12/02/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E6%80%BB%E8%A7%88/)
- [深度强化学习博客链接](https://coladrill.github.io/2018/10/21/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%BB%BC%E8%BF%B0/)

> 本文综述方面的内容绝大部分来自于[这篇论文](https://arxiv.org/pdf/1810.13306.pdf)，文中的引用序号可参见原文的引用来查找论文。

### 引言

机器学习技术深深植根于我们的日常生活中。然而，由于追求良好的学习成绩是知识和劳动密集型的，因此人类专家大量参与机器学习的各个方面。为了使机器学习技术更容易应用并减少对经验丰富的人类专家的需求，自动机器学习（AutoML）已成为工业和学术界的热门话题。

### AutoML定义

AutoML不仅希望具有良好的学习性能（从机器学习的角度来看），而且还要求在没有人工协助的情况下实现这种性能（从自动化的角度来看）。 因此，AutoML的非正式和直观描述可以表示为
![](/img/post/20181207/1.png)

> `定义1 机器学习`：计算机程序先从某些类别的`任务T`和`性能测量P`中`经验E`中学习，如果其性能可以通过P测量的E在T上得到改善。

> `定义2 AutoML `: AutoML尝试构建机器学习程序（由定义1中的E，T和P指定），无需人工协助且在有限的计算预算内。

为了更好地理解定义2，表1中举出了三个例子：
![](/img/post/20181207/2.png)

- `自动模型选择`：这里，**E表示输入训练数据，T表示分类任务，P表示给定任务的准确性**。当给出特征时，Auto-sklearn可以选择合适的分类器并在没有人工帮助的情况下找到相应的超参数。
- `神经结构搜索`：当我们尝试在NAS的帮助下进行一些图像分类问题时，**E是图像的集合，T是图像分类问题，P是测试图像的准确性**。 NAS将自动搜索神经架构，即基于神经网络的分类器，其在给定任务上具有良好性能。
- `自动特征工程`：由于输入特征可能不够丰富，我们可能需要构建更多特征以提高学习效果。在这种情况下，**E是原始特征，T是特征的构造，P是用构造的特征学习的模型的性能**。 [DSM](https://ieeexplore.ieee.org/document/7344858)和[ExploreKit](https://people.eecs.berkeley.edu/~dawnsong/papers/icdm-2016.pdf)通过基于输入要素之间的交互自动构建新要素来消除人工辅助。

最后，请注意，定义2足以涵盖大多数可被视为自动的机器学习方法。 根据这个定义，具有固定配置的机器学习管道也不会根据不同的E，T和P进行调整，这也是自动的。 

**AutoML目标：**
- 更好的性能：在各种输入数据和学习任务中具有良好的泛化性能;
- 没有人类的帮助：可以自动完成机器学习工具的配置; 
- 较低的计算预算：该计划可以在有限的预算内返回产出。

### AutoML框架

在表2中，我们使用表1中的示例来演示`拟议框架`如何涵盖现有工作：
![](/img/post/20181207/3.png)

#### AutoML控制器

![](/img/post/20181207/4.png)

**1、`评估器`l：使用优化程序提供的配置来衡量学习工具的性能，生成优化程序的反馈**
- 通常，为了使用给定配置测量学习工具的性能，评估器需要根据输入数据训练模型，这可能非常耗时。
- 然而，评估器还可以基于模仿人类经验的外部知识直接估计绩效。 这种估计非常快，但可能不准确。 
- 因此，对于评估器来说，它需要快速但准确地测量学习工具的性能。

**2、`优化器`：更新或生成学习工具的配置** 
- 优化器的搜索空间由学习工具定义，并且新配置预期比以前的配置具有更好的性能。
- 但是，评估器提供的反馈不必由优化器使用。 这取决于我们正在使用哪种类型的优化算法。 
- 最后，当优化器在搜索空间上运行时，我们希望搜索空间可以轻松紧凑，以便优化器可以通过一些生成的配置识别出良好的配置。

> 优化器专注于搜索和优化配置，可以使用许多方法，从`网格搜索`和`随机搜索`等简单方法到非常复杂的方法，如`强化学习`和`自动差异化（automatic differentiation）`。 

> 然而，对于主要通过确定其参数来测量具有当前配置的学习工具的性能的评估器，可以采用很多方法作为基本方法。

#### 现有方法分类

表3. 通过问题设置对现有AutoML方法进行分类。
![](/img/post/20181207/5.png)

### 特征工程

在许多情况下，来自数据的`原始特征`可能不够好，例如，它们的维度可能太高或者样本在特征空间中可能不可辨别。 因此，我们可能希望对这些特征进行一些后处理。 

特征工程进一步分为两个子问题：`从数据创建特征`、`增强特征的辨别能力`。**在这里，我们专注于特征增强方法。**

**1、降维**：通过获取一组主要变量来减少所考虑的随机变量数量的过程。

这在特征之间存在大量冗余或特征维度过高时非常有用。它可以分为特征选择和特征投影。 
- 特征选择：试图从原始特征选择特征的子集，流行的方法是贪婪搜索和套索。
- 特征投影：将原始特征转换为新的空间，其尺寸要小得多，例如PCA，LDA和最近的自动编码器。

**2、特征编码**：根据从数据中学习的一些字典重新解释原始特征。 

在编码之后，样本通常在另一个特征空间中被提升，这比原始特征空间高得多。 由于字典可以捕获训练数据中的协作表示，因此在原始空间中不可辨别的样本在新空间中变得可分离。
- 稀疏编码方法[68]：卷积变体[69]、局部线性编码[70]。
- 内核方法：也可以看作特征编码，其中基函数是字典。 但是，内核方法必须与SVM一起使用，基本函数是手工设计的，不是由数据驱动的。

**3、特征生成**：基于一些预定义的操作[ref]来构造来自原始特征的新特征。

由于原始特征是由人类设计的，因此它们之间通常存在未经探索的相互作用，这可以显着提高学习成绩。
- 两个特征的乘法和标准归一化。 
- 它通常被建模为原始特征操作所跨越的空间中的搜索问题。 已经应用了许多搜索算法，例如贪婪搜索[9]和进化算法[45]，[67]。

**上述操作会产生两类搜索空间，对应两种配置（configuration）**：
- 第一类由这些工具的超参数组成，配置正是指这些超参数。
	- 它包括降维和特征编码方法，（例如[5]，[6]，[34]）。 例如，我们需要确定PCA之后的特征维度，以及稀疏编码的稀疏程度。
- 第二类搜索空间来自特征生成（例如[9]，[10]，[45]，[46]，[47]）。 通过预定义操作与原始特征的组合来跨越空间。 
	- plus，minus和times操作生成的新特征的一个示例。对于这些方法，配置是搜索空间中特征的选择。

### 模型选择

在文献中已经提出了许多分类工具，例如`线性分类器`，`树分类器`，`内核机器`以及最近的`深度网络`。**每个分类器在数据下的建模中都有自己的优势和劣势。**例如，树分类器通常优于线性分类器。 然而，当特征维度变高时，它变得非常昂贵并且难以训练树分类器。

传统上，不同分类器之间的选择通常由人类根据他的经验以反复试验的方式进行。从表4中可以看出，每个分类器还有与其相关联的超参数。
![](/img/post/20181207/6.png)

模型选择同样分为两个子问题：`自动选择分类器`、`设置其超参数`。

从上面，我们可以看到在模型选择的上下文中的配置是分类器及其超参数的选择（例如[5]，[34]，[37]，[48]，[49]）。 这两部分构成了搜索空间。 
- 分类器的选择可以简单地建模为离散变量，1表示使用分类器，0表示不使用。 
- 超参数的属性取决于模型的设计和实现。例如，最近邻居的数量是离散的，而逻辑回归的惩罚参数是连续的。

机器学习的最后和最耗时的步骤是找到学习工具的参数，通常涉及优化工具。 在过渡方面，由于优化工具通常非常简单，优化不是一个问题，从各种优化工具获得的性能几乎相同。**效率是选择优化工具的主要焦点。**

表5总结了一些用于`最小化平滑目标函数`的`常用工具`，如`逻辑回归`。
![](/img/post/20181207/7.png)
- 虽然`GD`不涉及任何额外参数，但它的收敛速度慢且每次迭代复杂度很高。 
- `L-BFGS`更昂贵但收敛速度更快。
- 每次迭代在`SGD`中都非常便宜，但在收敛之前需要进行多次迭代。

未完待续...

