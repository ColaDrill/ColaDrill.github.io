---
layout:     post
title:      自动机器学习总览
subtitle:   A Survey on Automated Machine Learning
date:       2018-12-07
author:     Jiayue Cai
header-img: img/post-bg-ai.jpg
catalog: true
tags:
    - Machine Learning
    - Automated Machine Learning
---


> Last updated on 2018-12-08...

- [元学习博客链接](https://coladrill.github.io/2018/10/24/%E5%85%83%E5%AD%A6%E4%B9%A0%E6%80%BB%E8%A7%88/)
- [强化学习博客链接](https://coladrill.github.io/2018/12/02/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E6%80%BB%E8%A7%88/)
- [深度强化学习博客链接](https://coladrill.github.io/2018/10/21/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%BB%BC%E8%BF%B0/)

> 本文综述方面的内容绝大部分来自于[这篇论文](https://arxiv.org/pdf/1810.13306.pdf)，文中的引用序号可参见原文的引用来查找论文。

### 引言

机器学习技术深深植根于我们的日常生活中。然而，由于追求良好的学习成绩是知识和劳动密集型的，因此人类专家大量参与机器学习的各个方面。为了使机器学习技术更容易应用并减少对经验丰富的人类专家的需求，自动机器学习（AutoML）已成为工业和学术界的热门话题。

### AutoML定义

AutoML不仅希望具有良好的学习性能（从机器学习的角度来看），而且还要求在没有人工协助的情况下实现这种性能（从自动化的角度来看）。 因此，AutoML的非正式和直观描述可以表示为
![](/img/post/20181207/1.png)

> `定义1 机器学习`：计算机程序先从某些类别的`任务T`和`性能测量P`中`经验E`中学习，如果其性能可以通过P测量的E在T上得到改善。

> `定义2 AutoML `: AutoML尝试构建机器学习程序（由定义1中的E，T和P指定），无需人工协助且在有限的计算预算内。

为了更好地理解定义2，表1中举出了三个例子：
![](/img/post/20181207/2.png)

- `自动模型选择`：这里，**E表示输入训练数据，T表示分类任务，P表示给定任务的准确性**。当给出特征时，Auto-sklearn可以选择合适的分类器并在没有人工帮助的情况下找到相应的超参数。
- `神经结构搜索`：当我们尝试在NAS的帮助下进行一些图像分类问题时，**E是图像的集合，T是图像分类问题，P是测试图像的准确性**。 NAS将自动搜索神经架构，即基于神经网络的分类器，其在给定任务上具有良好性能。
- `自动特征工程`：由于输入特征可能不够丰富，我们可能需要构建更多特征以提高学习效果。在这种情况下，**E是原始特征，T是特征的构造，P是用构造的特征学习的模型的性能**。 [DSM](https://ieeexplore.ieee.org/document/7344858)和[ExploreKit](https://people.eecs.berkeley.edu/~dawnsong/papers/icdm-2016.pdf)通过基于输入要素之间的交互自动构建新要素来消除人工辅助。

最后，请注意，定义2足以涵盖大多数可被视为自动的机器学习方法。 根据这个定义，具有固定配置的机器学习管道也不会根据不同的E，T和P进行调整，这也是自动的。 

**AutoML目标：**
- 更好的性能：在各种输入数据和学习任务中具有良好的泛化性能;
- 没有人类的帮助：可以自动完成机器学习工具的配置; 
- 较低的计算预算：该计划可以在有限的预算内返回产出。

### AutoML框架

在表2中，我们使用表1中的示例来演示`拟议框架`如何涵盖现有工作：
![](/img/post/20181207/3.png)

#### AutoML控制器

![](/img/post/20181207/4.png)

**1、`评估器`：使用优化程序提供的配置来衡量学习工具的性能，生成优化程序的反馈**
- 通常，为了使用给定配置测量学习工具的性能，评估器需要根据输入数据训练模型，这可能非常耗时。
- 然而，评估器还可以基于模仿人类经验的外部知识直接估计绩效。 这种估计非常快，但可能不准确。 
- 因此，对于评估器来说，它需要快速但准确地测量学习工具的性能。

**2、`优化器`：更新或生成学习工具的配置** 
- 优化器的搜索空间由学习工具定义，并且新配置预期比以前的配置具有更好的性能。
- 但是，评估器提供的反馈不必由优化器使用。 这取决于我们正在使用哪种类型的优化算法。 
- 最后，当优化器在搜索空间上运行时，我们希望搜索空间可以轻松紧凑，以便优化器可以通过一些生成的配置识别出良好的配置。

> 优化器专注于搜索和优化配置，可以使用许多方法，从`网格搜索`和`随机搜索`等简单方法到非常复杂的方法，如`强化学习`和`自动差异化（automatic differentiation）`。 

> 然而，对于主要通过确定其参数来测量具有当前配置的学习工具的性能的评估器，可以采用很多方法作为基本方法。

#### 现有方法分类

表3. 通过问题设置对现有AutoML方法进行分类。
![](/img/post/20181207/5.png)

### 特征工程

在许多情况下，来自数据的`原始特征`可能不够好，例如，它们的维度可能太高或者样本在特征空间中可能不可辨别。 因此，我们可能希望对这些特征进行一些后处理。 

特征工程进一步分为两个子问题：`从数据创建特征`、`增强特征的辨别能力`。**在这里，我们专注于特征增强方法。**

**1、降维**：通过获取一组主要变量来减少所考虑的随机变量数量的过程。

这在特征之间存在大量冗余或特征维度过高时非常有用。它可以分为特征选择和特征投影。 
- 特征选择：试图从原始特征选择特征的子集，流行的方法是贪婪搜索和套索。
- 特征投影：将原始特征转换为新的空间，其尺寸要小得多，例如PCA，LDA和最近的自动编码器。

**2、特征编码**：根据从数据中学习的一些字典重新解释原始特征。 

在编码之后，样本通常在另一个特征空间中被提升，这比原始特征空间高得多。 由于字典可以捕获训练数据中的协作表示，因此在原始空间中不可辨别的样本在新空间中变得可分离。
- 稀疏编码方法[68]：卷积变体[69]、局部线性编码[70]。
- 内核方法：也可以看作特征编码，其中基函数是字典。 但是，内核方法必须与SVM一起使用，基本函数是手工设计的，不是由数据驱动的。

**3、特征生成**：基于一些预定义的操作[ref]来构造来自原始特征的新特征。

由于原始特征是由人类设计的，因此它们之间通常存在未经探索的相互作用，这可以显着提高学习成绩。
- 两个特征的乘法和标准归一化。 
- 它通常被建模为原始特征操作所跨越的空间中的搜索问题。 已经应用了许多搜索算法，例如贪婪搜索[9]和进化算法[45]，[67]。

**上述操作会产生两类搜索空间，对应两种配置（configuration）**：
- 第一类由这些工具的超参数组成，配置正是指这些超参数。
	- 它包括降维和特征编码方法，（例如[5]，[6]，[34]）。 例如，我们需要确定PCA之后的特征维度，以及稀疏编码的稀疏程度。
- 第二类搜索空间来自特征生成（例如[9]，[10]，[45]，[46]，[47]）。 通过预定义操作与原始特征的组合来跨越空间。 
	- plus，minus和times操作生成的新特征的一个示例。对于这些方法，配置是搜索空间中特征的选择。

### 模型选择

在文献中已经提出了许多分类工具，例如`线性分类器`，`树分类器`，`内核机器`以及最近的`深度网络`。**每个分类器在数据下的建模中都有自己的优势和劣势。**例如，树分类器通常优于线性分类器。 然而，当特征维度变高时，它变得非常昂贵并且难以训练树分类器。

传统上，不同分类器之间的选择通常由人类根据他的经验以反复试验的方式进行。从表4中可以看出，每个分类器还有与其相关联的超参数。
![](/img/post/20181207/6.png)

模型选择同样分为两个子问题：`自动选择分类器`、`设置其超参数`。

从上面，我们可以看到在模型选择的上下文中的配置是分类器及其超参数的选择（例如[5]，[34]，[37]，[48]，[49]）。 这两部分构成了搜索空间。 
- 分类器的选择可以简单地建模为离散变量，1表示使用分类器，0表示不使用。 
- 超参数的属性取决于模型的设计和实现。例如，最近邻居的数量是离散的，而逻辑回归的惩罚参数是连续的。

### 算法选择

机器学习的最后和最耗时的步骤是找到学习工具的参数，通常涉及优化工具。 在过渡方面，由于优化工具通常非常简单，优化不是一个问题，从各种优化工具获得的性能几乎相同。**效率是选择优化工具的主要焦点。**

表5总结了一些用于`最小化平滑目标函数`的`常用工具`，如`逻辑回归`。
![](/img/post/20181207/7.png)
- 虽然`GD`不涉及任何额外参数，但它的收敛速度慢且每次迭代复杂度很高。 
- `L-BFGS`更昂贵但收敛速度更快。
- 每次迭代在`SGD`中都非常便宜，但在收敛之前需要进行多次迭代。

传统上，优化工具的选择及其超参数都是由人类完成的。这些再次基于人类对学习工具的理解和对训练数据的观察。 

搜索空间由优化工具的配置决定，优化工具包含优化工具的选择及其超参数的值（例如[38]，[50]，[51]，[52]，[53]）。

### 全范围

其实`搜索`可以通过两种方式完成:
- 分别重复使用`每个`设置的方法然后将它们`组合`在一起。（即`分层结构`，例如[5]，[6]，[21]，[34]）
- `直接`搜索所有配置所跨越的空间。 （`NAS`）

> `网络架构搜索（NAS）`，其目标是搜索深层网络的良好架构（例如[7]，[20]，[40]，[54]，[55]，[56]，[ 57]，[58]，[59]，[60]，[61]，[62]，[72]）。

在描述NAS的搜索空间之前，让我们回顾一下典型的CNN架构：
![](/img/post/20181207/8.png)

深层网络的模型复杂性也可以用于搜索，即我们可以`再添加一层或跳转连接层之间的关系`。这种关键差异是在NAS中使用强化学习[19]的动机。 
因此，搜索空间由上述设计选择和SGD中的超参数组成。 这里针对NAS的一种配置是这种搜索空间中的一个点。
![](/img/post/20181207/9.png)

> 这里提出的想法可以类似地应用于其他深层架构，如长期短期记忆（LSTM）[75]和深度稀疏网络[76]。

> 在NAS中，由于一些设计选择是离散的而不是差分的，因此在[41]中使用soft-max将搜索空间改变为差分，这使得能够使用梯度下降而不是RL。

### 优化器的基本技术

优化问题，简言之就是在自变量定义域中选择一个较优自变量使得因变量最优。
![](/img/post/20181207/10.png)

**这里有三个重要问题：**
- 优化器可以运行什么样的搜索空间？
- 它需要什么样的反馈？
- 在找到一个好的配置之前需要生成/更新多少配置？

前两个问题决定了哪种类型的技术可用于优化器，最后一个问题阐明了技术的效率。虽然效率也是AutoML的一大追求（参见备注2.1），但我们并未根据它对现有技术进行分类。

基于前两个问题有两种简单搜索方法：`样本优化`、`梯度下降`。 表6列出了这些技术之间的简要对比：
![](/img/post/20181207/11.png)

#### 简单搜索方法

- `网格搜索`必须枚举搜索空间中的每个可能的配置。因此，当搜索空间连续时，离散化是必要的。 
- `随机搜索`[42]可以更好地探索搜索空间，因为将评估更多的位置。

![](/img/post/20181207/12.png)

#### 基于样本的优化

基于样本的优化[77]是一种更智能的搜索方法，与简单搜索方法相比，它会根据以前的配置迭代生成新配置。 

根据不同的优化策略，我们将现有方法分为三类，即`启发式搜索`，`基于模型的无导数优化`和`强化学习`。

**1、启发式搜索**

启发式搜索方法通常受到生物行为和现象的启发。
![](/img/post/20181207/13.png)

- `粒子群优化（PSO）`[48]：PSO受到鸟类植绒或鱼类学校教育的社会行为的启发。 它通过`搜索最佳样本周围的局部区域`进行优化。 PSO本身具有很少的超参数，并且易于并行化。
- `进化算法`[78]：进化算法受到生物进化的启发。`突变和选择`是主要组成部分。 一些最先进的方法，如CMA-ES[79]，用于解决各种复杂的优化问题。

> 上述方法已应用于AutoML（例如，[45]，[48]，[80]，[81]，[82]，[83]，[84]），

**2、基于模型的无导数优化**

基于访问样本构建模型，这有助于生成更有前途的新样本。
![](/img/post/20181207/14.png)

- `贝叶斯优化`[85][86]：贝叶斯优化通过高斯过程或其他模型（例如决策树[87]，随机森林[88]）在搜索空间上建立概率代理函数。然后，它通过优化基于代理函数的采集特征来选择下一个样本。由于在昂贵的优化方面具有出色的性能，`贝叶斯优化在AutoML中得到了广泛的应用。`
- `基于分类的优化`[39][89]：基于先前的样本，基于分类的优化模型通过学习分类器来搜索空间。通过分类，搜索空间分为正面和负面区域。然后，在阳性区域上生成新样本，从中可以获得更好的样本。模型方法简单有效。因此，基于分类的优化具有高效率和良好的可扩展性。
- `同步乐观优化`（Simultaneous Optimistic Optimization, `SOO`）[90]：SOO应用树结构来平衡搜索空间的探索和开发。当目标函数是局部Lipschitz连续时，SOO可以得到全局最优。但它也遭受了维度的诅咒，因为当目标函数的维数很高时，树的生长会变得极其艰难。

**3、强化学习**

强化学习（RL）[19]是一个非常通用和强大的优化框架，可以解决延迟反馈的问题。 
![](/img/post/20181207/15.png)

> RL已广泛用于NAS（[7]，[13]，[20]，[21]，[91]，[92]）。 

（这里准确来说是DRL）优点是CNN可以逐层构建，并且一层的设计可以看作是生成器给出的一个动作。 因此，迭代架构生成自然遵循RL的属性。

然而，再次由于反馈延迟，具有强化学习的AutoML消耗很大，需要探索更有效的方法。

#### 梯度下降

因为AutoML的优化问题非常复杂，这可能`不是可区分的`，甚至也`不是连续的`。因此，梯度下降很难成为有效的优化器。然而，关注一些`可微分损失函数`[93]，例如`平方损失`和`逻辑损失`，可以通过梯度下降来优化连续超参数。

与传统的优化问题不同，传统优化问题的梯度可以从目标中明确得出，这里需要`隐式计算梯度`。
- 通常，这可以通过`有限区分`来完成[93]。
- 另一种计算精确梯度的方法是通过`可逆学习`[36]，[43]，[94]。它已应用于深度学习超参数搜索。对于传统的机器学习，提出了`近似梯度`来搜索连续超参数[95]。通过这种不精确的梯度，可以在模型参数收敛之前更新超参数。

### 评估器的基本技术

**这里有一些重要问题：**
- 该技术能否提供快速评估？
- 该技术能否提供准确的评估？
- 评估器需要提供什么样的反馈？

未完待续...






















