---
layout:     post
title:      浅谈BLEU评分
subtitle:   From Neural Machine Translation
date:       2018-10-20
author:     Jiayue Cai
header-img: img/post-bg-black.jpg
catalog: true
tags:
    - NLP
    
---


>>Last updated on 2018-10-20... 

BLEU，全称为Bilingual Evaluation Understudy（双语评估替换），是一种对`生成语句`进行`评估的指标`，用于比较候选文本翻译与其他一个或多个参考翻译的评价分数。

BLEU评分是由Kishore Papineni等人2002年的论文[《BLEU: a Method for Automatic Evaluation of Machine Translation》](http://www.aclweb.org/anthology/P02-1040.pdf)中提出的。

这种评分标准是为了评估自动机器翻译系统的预测结果而开发的。
- 优点：计算速度快、计算成本低、容易理解、与具体语言无关、和人类给的评估高度相关。
- 缺点：不考虑语言表达（语法）上的准确性；测评精度会受常用词的干扰；短译句的测评精度有时会较高；没有考虑同义词或相似表达的情况，可能会导致合理翻译被否定。

除了翻译之外，BLEU评分结合深度学习方法可应用于其他的语言生成问题，例如：语言生成、图片标题生成、文本摘要、语音识别。

本文主要参考文章：[链接1](https://blog.csdn.net/qq_31584157/article/details/77709454)、[链接2](https://blog.csdn.net/qq_21190081/article/details/53115580)、[链接3](https://cloud.tencent.com/developer/article/1042161)

### n单位片段精确度

#### n-gram precision

1、**n单位片段(`n-gram`)**：指一个语句里面连续的n个单词组成的片段，一个18单词的语句有18个1-gram，每个单词都是一个1-gram；有17个2-gram，这个很好理解。

2、**精确度(`precision`)**：指Candidate语句里面的n-gram在所有Reference语句里面出现的概率。

**Example 1：**

Candidate 1：It is a guide to action which ensures that the military always obeys the commands of the party.

Candidate 2: It is to insure the troops forever hearing the activity guidebook that party direct.

> Reference 1: It is a guide to action that ensures that the military will forever heed Party commands.

> Reference 2: It is the guiding principle which guarantees the military forces always being under the command of the Party.

> Reference 3: It is the practical guide for the army always to heed the directions of the party .

在Example 1的Candidate 1 语句中，18个单词共有17个单词出现过，所以1-gram的precision是17/18；17个2-gram片段总共有10个出现过，所以2-gram的precision是10/17。

**Example 2：**

Candidate: the the the the the the the.

> Reference 1: The cat is on the mat.

> Reference 2: There is a cat on the mat.

在Example 2的Candidate 语句1-gram的Precision是7/7。

所以我们发现这个方法存在一个问题，就是可能Reference里面的单词会被重复利用，这是不合理的。所以有了“修正的n-单位精确度”(modified n-gram recision)。

#### modified n-gram recision

**修正的n-单位精确度**：主要思路是Reference语句里面如果一个单词片段已经被匹配，那么这个片段就不能再次被匹配，并且一个单词片段只能取一个Reference语句中出现次数的最大值，比如7个the分别在Reference 1 和 2中出现2和1次，所以取2而不是两者相加的3。

利用以上方法，每一个句子都可以得到一个modified n-gram recision，一个句子不能代表文本翻译的水平高低，于是把一段话或者所有翻译句子的结果综合起来可以得到p<sub>n</sub>
![pn](https://upload-images.jianshu.io/upload_images/13187322-f62bf40335e3cbc6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/404/format/webp)

简而言之，就是把所有句子的modified n-gram precision的分子加起来除以分母加起来。

### BP值(Brevity Penalty)

对于不同的长度n都会有一个p<sub>n</sub>，那么如何将不同n的p<sub>n</sub>结合起来得到最终的Bleu值。研究者们还考虑到一种情况，就是待测译文翻译不完全不完整的情况，这个问题在机器翻译中是不能忽略的，而简单的p<sub>n</sub>值不能反映这个问题，例如Example 3。

**Example 3：**

Candidate: of the

> Reference 1: It is a guide to action that ensures that the military will forever heed Party commands.

> Reference 2: It is the guiding principle which guarantees the military forces always being under the command of the Party.

> Reference 3: It is the practical guide for the army always to heed the directions of the party.

这个问题也不能用recall来解决，例如Example 4. 显然Candidate 1的回召率比Candidate 2要高，但是显然Candidate 1的翻译不如Candidate 2。所以recall并不能解决这个问题。

**Example 4：**

Candidate 1: I always invariably perpetually do.

Candidate 2: I always do.

> Reference 1: I always do.

> Reference 2: I invariably do.

> Reference 3: I perpetually do.

首先引入BP值，作者指定当待评价译文同任意一个参考译文长度相等或超过参考译文长度时，BP值为1，当待评价译文的长度较短时，则用一个算法得出BP值。
以c来表示待评价译文的长度，r来表示参考译文的文字长度，则
![1](https://upload-images.jianshu.io/upload_images/13187322-0eee8a59055c4903.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/207/format/webp)

之后又Bleu值等于
![2](https://upload-images.jianshu.io/upload_images/13187322-252a0f9a7b5cee6f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/256/format/webp)

在对数情况下，计算变得更加简便
![3](https://upload-images.jianshu.io/upload_images/13187322-a9871645d9e84a50.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/339/format/webp)









