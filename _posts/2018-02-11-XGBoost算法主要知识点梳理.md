---
layout:     post
title:      XGBoost算法
subtitle:   主要知识点梳理
date:       2018-02-11
author:     Jiayue Cai
header-img: img/post-bg-debug.png
catalog: true
tags:
    - Machine Learning
---


>仅主要知识点梳理

### 引言

XGBoost的全称 `eXtreme Gradient Boosting`，2014年2月诞生的专注于梯度提升算法的机器学习函数库，作者为华盛顿大学研究机器学习的大牛——**`陈天奇`**。他在研究中深深的体会到现有库的计算速度和精度问题，为此而着手搭建完成 xgboost 项目。xgboost问世后，因其优良的学习效果以及高效的训练速度而获得广泛的关注，并在各种算法大赛上大放光彩……

本文主要对XGBoost的原理进行了一个简要梳理，方便大家能从中捕获一些知识点，同时在此特别感谢北大的wepon同学的分享。在阅读此篇之前，建议参读顺序为：**`最优化算法（梯度下降和牛顿法）`**->**`GBDT`**->**`XGBoost`**。
 
### 主要知识点 

![](http://img.blog.csdn.net/20180211125658834?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvenoyMzIzMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
![](http://img.blog.csdn.net/20180211125732539?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvenoyMzIzMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
![](http://img.blog.csdn.net/20180211125812296?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvenoyMzIzMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
![](http://img.blog.csdn.net/20180211125847854?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvenoyMzIzMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
![](http://img.blog.csdn.net/2018021112591811?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvenoyMzIzMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
![](http://img.blog.csdn.net/20180211125937111?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvenoyMzIzMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
	
	
### 结束语

到此，XGboost的主要内容已全部梳理完，对于其算法的其他特性，可以参读原文`《XGBoost: A Scalable Tree Boosting System 》`。
	


